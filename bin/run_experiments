#!/usr/bin/env python3
"""
Run experiments
"""
import torch
import argparse
import importlib
from statistics import mean, pstdev

from dgl.data import register_data_args, load_data

from utils.inits import to_cuda
from utils.io import print_graph_stats, read_params, save_results, create_default_path, remove_model

from core.data.constants import GRAPH, N_RELS, N_CLASSES, N_ENTITIES
from core.models.constants import (
    AIFB, MUTAG, MUTAGENICITY, PTC_FM, PTC_FR, PTC_MM, PTC_MR,
    NODE_CLASSIFICATION, GRAPH_CLASSIFICATION
)
from core.models.model import Model
from core.app import App


MODULE = 'core.data.{}'
AVAILABLE_DATASETS = {
    'dglrgcn',
    'dortmund'
}


def main(args):

    if args.gpu < 0:
        cuda = False
    else:
        cuda = True
        torch.cuda.set_device(args.gpu)

    module_rgcn = importlib.import_module(MODULE.format('dglrgcn'))
    module_dortmund = importlib.import_module(MODULE.format('dortmund'))

    config_params = read_params(args.config_fpath, verbose=True)
    n_exp = len(config_params)

    if not args.save_path and not args.load_path:
        default_path = create_default_path()
        print('make default save/load path', default_path)
        args.save_path = default_path
        args.load_path = default_path

    for exp_idx in range(n_exp):
        accuracies = []
        learning_config = {'lr': args.lr,
                           'n_epochs': args.n_epochs,
                           'weight_decay': args.weight_decay,
                           'batch_size': args.batch_size,
                           'cuda':cuda
                           }
        for i in range(args.repeat):
            # 1. load data
            if args.dataset == AIFB or args.dataset == MUTAG:
                data = module_rgcn.load_dglrgcn(args.data_path)
                data = to_cuda(data) if cuda else data
                mode = NODE_CLASSIFICATION
            elif args.dataset == MUTAGENICITY or args.dataset == PTC_MR or args.dataset == PTC_MM or args.dataset == PTC_FR or args.dataset == PTC_FM:
                data = module_dortmund.load_dortmund(args.data_path)
                data = to_cuda(data) if cuda else data
                mode = GRAPH_CLASSIFICATION
            else:
                raise ValueError('Unable to load dataset', args.dataset)

            print_graph_stats(data[GRAPH])

            # 2. create GNN model
            print('Config:', config_params)
            current_config = config_params[exp_idx].copy()
            model = Model(g=data[GRAPH],
                          config_params=current_config,
                          n_classes=data[N_CLASSES],
                          n_rels=data[N_RELS] if N_RELS in data else None,
                          n_entities=data[N_ENTITIES] if N_ENTITIES in data else None,
                          is_cuda=cuda,
                          mode=mode)
            if cuda:
                model.cuda()

            # 3. train model
            app = App(model)
            print(mode)
            app.train(data, current_config, learning_config, save_path=args.save_path, mode=mode)

            # 4. test model
            acc = app.test(data, args.load_path, mode=mode)
            accuracies.append(acc)

        print('Average testing accuracy over {:03d} is {:.3f}'.format(args.repeat, mean(accuracies)))

        # write result
        result = {}
        result['config'] = config_params[exp_idx]
        result['learning_params'] = learning_config
        result['acc'] = {'dataset': args.dataset,
                         'avg': mean(accuracies),
                         'std': pstdev(accuracies),
                         'repeat': args.repeat,
                         'values': accuracies,
                         'data_path': args.data_path}
        print('result', result)
        save_results(result, verbose=True)

        # remove tmp model generated
        remove_model(default_path)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Run graph neural networks.')
    register_data_args(parser)
    parser.add_argument("--config_fpath", type=str, required=True,
                        help="Path to JSON configuration file.")
    parser.add_argument("--data_path", type=str, required=True,
                        help="Path from where to load the data (assuming they were preprocessed beforehand).")
    parser.add_argument("--gpu", type=int, default=-1, help="gpu")
    parser.add_argument("--repeat", type=int, default=1, help="number of times a training must be repeated")
    parser.add_argument("--lr", type=float, default=1e-2,
                        help="learning rate")
    parser.add_argument("--n-epochs", type=int, default=200,
                        help="number of training epochs")
    parser.add_argument("--weight-decay", type=float, default=5e-4,
                        help="Weight for L2 loss")
    parser.add_argument("--save_path", type=str, required=False,
                        help="Path where to save the trained model.", default='')
    parser.add_argument("--load_path", type=str, required=False,
                        help="Path from where to load model.", default='')
    parser.add_argument("--batch-size", type=int, default=16, help="batch size (only for graph classification)")

    args = parser.parse_args()
    print(args)

    main(args)